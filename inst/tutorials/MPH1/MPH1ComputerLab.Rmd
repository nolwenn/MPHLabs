---
title: "Get started with R - MPH1 introduction course"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: >
  Learn how to read data, recode, filter observations in a data frame and perfom basic statiscal summary.
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
tutorial_options(
  exercise.timelimit = 60,
  # A simple checker function that just returns the message in the check chunk
  exercise.checker = function(check_code, ...) {
    list(
      message = eval(parse(text = check_code)),
      correct = logical(0),
      type = "info",
      location = "append"
    )
  }
)

options(tutorial.storage = list(
  # save an arbitrary R object "data" to storage
  save_object = function(tutorial_id, tutorial_version, user_id, object_id, data) {
  },
  # retrieve a single R object from storage
  get_object = function(tutorial_id, tutorial_version, user_id, object_id) { 
    NULL 
  },
  # retrieve a list of all R objects stored
  get_objects = function(tutorial_id, tutorial_version, user_id) { 
    list() 
  },
  # remove all stored R objects
  remove_all_objects = function(tutorial_id, tutorial_version, user_id) {
  }))
  
knitr::opts_chunk$set(error = TRUE, tutorial.data_dir="data")
load("../../data/sleepapnea.Rdata")
load("../../data/sleepapnea_clean.Rdata")
```

## Welcome

This is an **interactive version of the MPH1 computer labs** with the statistical software *R*. **Your objective is to learn the basic of R** while running online examples and trying some exercises. The tutorial uses the Sleep apnea data set, presented in the next section.

A dataset is the basic element in research. It contains units and variables. Individuals or statistical units are in rows, variables in columns. 

A table of this kind generally includes two kinds of variables: those used to identify the statistical units (in research, this is often a single anonymized variable, an identifier) and those measured for the study (measurements, socio-economic factors etc.).


### 

In this tutorial, you will learn how to:

-   read a dataset stored on your computer (as a CSV file)
-   explore the data format and the different type of variables
-   compute descriptive statistics
-   display plots
-   compute univariate statistical test
-   compute simple and multiple linear and logistic regression

Every R code chunk is link to a R engine and, when you hit the *Run code* button, the code is interpreted.

```{r example, exercise = TRUE, exercise.eval = FALSE}
```

To describe and analyze data in R, functions are needed. A package is a set of R functions and data-sets and the library is a folder on your system / computer which stores the files for those package(s). Packages can be installed thanks to the install.packages() basic function.

There are a lot of R functions. A function in R is one of the most used objects. It's very important to understand the purpose and syntax of R functions. Each function has a help page describing this function, its arguments and provides some examples. The *help()* function and *?* help operator in R provide access to the documentation pages for R functions.

As you get more familiar with R, you’ll begin to memorize basic functions - and Google is always there for the rest.

For the examples provided below, we invite you to run the code and for the exercises to first give it a try and then click on the **solution** button to check. We also invite you to go beyond the examples by adding arguments or completing with other R functions.


[As companion websites, we invite you to look at:]{.underline}

<https://nolwenn.github.io/ebook-M1-biostat/>

<https://nolwenn.github.io/software-M1-biostat/>

This tutorial has been developed by N. Le Meur in collaboration with A. Descarpentrie.

## The Sleep Apnea Study

All examples and proposed exercices are base on the Sleep Apnea study.

The present study deals with the sleep apnea problem. Sleep apnea is a sleep disorder characterizing by abnormal pauses in breathing during sleep. Each pause in breathing is called apnea.

Sleep apnea can affect anyone at any age. Well known risk factors for sleep apnea include being a male, overweight, age over 40, stress, and having a family history of sleep apnea. If left untreated, sleep apnea can result in a growing number of health problems, including high blood pressure, stroke, heart failure, irregular heartbeats, heart attacks, diabetes, fatigue, road accidents, and depression. Indeed, as some patients can stop breathing very often, for instance, 30 times in an hour, i.e. every 2 minutes, it means that they never get restful (or restorative) sleep. Therefore, they don't feel good during the day and their activity during the night cause stress for the heart. Prevalence of sleep apnea is estimated to be between 1 and 10% in the general population.

The main objective of this study is to explore in a French sample of population the determinants of the sleep apnea. The population was defined as the population hospitalized in the Rennes University hospital and aged more than 18 years old. A sampling procedure has been performed to select a random sample. Several individual characteristics have been collected. Their sleep has been monitored for a night (6 hours) and the number of pauses of breathing has been measured.

## Part A -- Reading and formatting data using R

### 1. Read data in R

Reading functions in *R* follows common rules with similar arguments. The most important are :

-   *file=* for the file name you need to read (with the path if not in your working directory)
-   *header=* to specify if your file contains a header with column names
-   *sep=* to specify the type of column separator (",", ";", "/")

The `read.csv()` function is a generic function to read tabulated data set. To store the output of the `read.csv()` function in a R object we use the assignment operator, `<-`. For example, here we name our object *sleepapnea* (the data.frame).

To give it a try, do one of the following:

- Place the cursor on the desired line and click the *Run Code* button (as mentioned before);
- Place the cursor on the desired line, hold the *control* key, and press enter. On macOS, hold *command* key and press return instead.


```{r read, exercise = TRUE, exercise.eval = FALSE, warnings=FALSE, message=FALSE}
sleepapnea <- read.csv(file="https://raw.githubusercontent.com/nolwenn/MPHLabs/main/data/SleepApnea.csv", header=TRUE, sep=",")
```

For a quick verification of the reading output, you can use the `head()` or `tail()` functions to observe the first 6 or last 6 rows for your R object *sleepapnea*.

Run the command below to test the `head()` function:

```{r header, exercise = TRUE, exercise.eval = FALSE}
head(sleepapnea)
```

Run the command in the code chunk below to test the `tail()` function:

```{r tail, exercise = TRUE, exercise.eval = FALSE}
tail(sleepapnea)
```

Try to modify the arguments of the `tail()` function to display the last 10 rows of your object (If you need help, use `?tail` in the code chunk):

```{r tailn10, exercise = TRUE}
```

```{r tailn10-solution}
tail(sleepapnea, n=10)
```

A final note : in R, variables, functions, and other objects have names. These names are case sensitive, so you must be careful when referencing an object by name or calling a function. We’ve been using the `head()` and `tail()` functions in the above examples, which begins with lower cases h and t, respectively.  There is no `Head()` and `Tail()` function:

```{r case_sensitivity, exercise = TRUE, exercise.eval = FALSE}
Head(sleepapnea)
Tail(sleepapnea)
```

**Good job!** You should now have a sense of :

-   what is a R function,
-   what are arguments for a function,
-   how to the store the result of your function call using the assignment operator, `<-`, so you keep and can reuse the result later on.

### 2. Data structure and variable types

To look at your data structure in the R console you can use the `str()` function:

```{r str, exercise = TRUE, exercise.eval = FALSE}
str(sleepapnea)
```

Your data set is a `data.frame` which is a rectangular R data format where variables can be of different types (e.g. numeric, integrer, character, factor...). The most common data type in R is *numeric*. A variable or a data series will be stored as numeric data if the values are numbers or if the values contains decimals. *Integer* and *double* data type are special cases of numeric data. Integers are numeric data without decimals and *double* are with decimals. The data type *character* is used when storing text, known as strings in R. *Factor* are used to manipulate categorical variables with levels (unique modalities) and labels. For instance, the gender variable will usually take on only two modalities with levels coded 1 and 2, and labeled “male” or “female” (note: in database where categorical variables are stored as character strings, R will read it as such, if not specified otherwise in the reading function, and you will need to transform the character vector into a factor).

**Looking at your object, is the output consistent with what you expected in terms of variables' types?**

Note: The output of `str()` is equivalent to the visual display of the blue dot with the white arrow tag to you object's name in the the *Environment panel* of RStudio

### 3. Data type conversion

The *number* variable in the sleep apnea data set corresponds to the anonymous identifier of each patient. It should not be a numeric value but a character or factor (categorical variable). From an analysis perspective, this variable is needed in order to merge two data sets containing the same statistical units (see the merge() function).

Note: You can use the dollar sign operator ($) in R to create and access variables in lists and data frames (here, the data.frame is "sleepapnea").

a.  First, we transform into character the *number* variable using the function `as.character()`. One way of doing is to overwrite the *number* variable by selecting the vector(variable) *number* in the data set using the `$` sign and applying the `as.character()`:

```{r tocharacter, exercise = TRUE, exercise.eval = FALSE}
sleepapnea$number <- as.character(sleepapnea$number)
```
You can also use the following option to proceed: sleepapnea[c('number')] <- as.character(sleepapnea$number)


Similarly, the *gender* variable should be a factor (categorical variable) and not a character: 

b.  Second, we need to transform the *gender* variable using `factor()`

```{r tofactor, exercise = TRUE, exercise.eval = FALSE}
summary(sleepapnea$gender)
sleepapnea$gender <- factor(sleepapnea$gender)
summary(sleepapnea$gender)
```

Note that we propose to use the summary function before and after to assess the result of applying the function.

c.  Similarly, we need to transform the *diabetes* variable (read as a numeric) into a categorical variable using the function `factor()` and setting the argument `labels=` to "No" and "Yes" to annotate the levels 0 and 1:

```{r tofactorwithlabels, exercise = TRUE, exercise.eval = FALSE}
summary(sleepapnea$diabetes)
sleepapnea$diabetes <- factor(sleepapnea$diabetes, levels = c(0,1),
                              labels=c("No","Yes"))
summary(sleepapnea$diabetes)
```

d.  To practice, rename the *Triglyceride_Cl_Ref* modalities using the existing *Triglyceride_Cl_Ref* variable knowing that:

-   classe 0 is $< 1.50$ or Normal rate
-   classe 1 is $1.50-1.99$ or Borderline rate
-   classe 2 is $2.00-4.99$ or High rate
-   classe 3 is $> 5.00$ or Very high rate

```{r TriglycerideCl, exercise = TRUE}
```

```{r TriglycerideCl-solution}
summary(sleepapnea$Triglyceride_Cl_Ref)
sleepapnea$Triglyceride_Cl_Ref <- factor(sleepapnea$Triglyceride_Cl_Ref, levels = c(0:3),
                              labels=c("Normal","Bordeline",
                                       "High", "Very High"))
summary(sleepapnea$Triglyceride_Cl_Ref)
```

Caution : **Every time you define a new variable or object with the same name as the original one, R overwrites the old value.** Therefore you should reuse variable or object names with caution, because it can become difficult to remember what the latest value was or you may need to correct a mistake made when categorizing a continuous variable! As for the *Triglyceride* variable (used to initially create the *Triglyceride_Cl_Ref* variable), try to have specific names for each new variable you create!

Of note: The *Triglyceride_Cl_Ref* variable was previously created, based on the continuous one (*Triglyceride*), and thanks to the ifelse() function. 

### 4. Save the clean data set

To keep the results of your pre-processing and data management steps, it is recommended that you use the `save()` function to create a *Rdata file* that contains the clean version of your data set:

```{r save, exercise = TRUE, exercise.eval = FALSE}
sleepapnea_clean <- sleepapnea
save(sleepapnea_clean, file="sleepapnea_clean.Rdata")
```

Or you can also write the resulting data.frame into a new CSV file that you will be able to open with other software such as Excel:

```{r writedata, exercise = TRUE, exercise.eval = FALSE}
write.csv(sleepapnea_clean, file="sleepapnea_clean.csv")
```
Final note: More often than not, you don’t need all dataset columns for your analysis. R provides a couple of ways to select columns of interest. For example, the subset() function might help you to do so.

## Part B - Descriptive Analysis

### 1. Load or read your clean data set

If you saved your data.frame in a *.Rdata file you can import the data in R using the `load` function:  

```{r load, eval = FALSE}
load("sleepapnea_clean.Rdata")
```

Note: in this tutorial, the import is done automatically by the library.

### 2. The summary() and table() functions

a.  Describe the variable gender using the functions `summary()` and `table()`:

```{r gendersummary, exercise = TRUE}
```

```{r gendersummary-solution}
summary(sleepapnea_clean$gender)
table(sleepapnea_clean$gender, useNA = "always")
```

b.  Compute contingency table between *gender* and *diabetes* using the function `table()`:

```{r gender2diabetes, exercise = TRUE}
```

```{r gender2diabetes-solution}
table("gender"=sleepapnea_clean$gender, "diabetes"=sleepapnea_clean$diabetes)
```

Using `prop.table()` to compute the proportion of diabetes among female and male:

```{r propgender2diabetes, exercise = TRUE}
```

```{r propgender2diabetes-solution}
round(prop.table(table("gender"=sleepapnea_clean$gender, "diabetes"=sleepapnea_clean$diabetes), margin=1)*100, 2)
#Of note, "margin=2" will provide you with the proportion of females and males among those with and without diabetes
```

c.  Describe the variable age using the function `summary()`:

```{r agesummary, exercise = TRUE}
```

```{r agesummary-solution}
summary(sleepapnea_clean$age)
```

d.  Compute the mean, standard deviation, mediane, quartiles for the variable age:

```{r agedesc, exercise = TRUE}
```

```{r agedesc-solution}
mean(sleepapnea_clean$age, na.rm=TRUE) #The “na.rm=T” argument is to be used when there are missing data for a variable 
sd(sleepapnea_clean$age, na.rm=TRUE)
median(sleepapnea_clean$age, na.rm=TRUE)
quantile(sleepapnea_clean$age, na.rm=TRUE) #the quantile() function provides by default quartiles, min and max
quantile(sleepapnea_clean$age, probs= c(0, 0.3, 0.6), na.rm=TRUE) #extra example 
```

A note about missing values: In *R*, missing values are represented by a reserved (special) value - NA. The following are useful base R functions when assessing or handling missing values: is.na() and !is.na(). For a specific variable, use is.na() to identify missing values, or use its opposite (with ! in front) to identify non-missing values. These both return a logical value (TRUE or FALSE). Remember that you can sum() the resulting vector to count the number TRUE. The gg_miss_var() function (from the *naniar* package) will show you the number (or %) of missing values in each column of your data set/data frame.

```{r na}
#For the age variable
sum(is.na(sleepapnea_clean$age))

#For the SleepApnea variable
sum(is.na(sleepapnea_clean$SleepApnea))

#For the whole original data set (*sleepapnea*)
library(naniar)
gg_miss_var(sleepapnea)

```

e.  What is the best graph for the variable age?

```{r agehistogram, exercise = TRUE, exercise.eval = FALSE}
hist(sleepapnea_clean$age, main="distribution of age", xlab="age (years)")
```

Draw the age distribution using the hist() function. Choose a width of age class of 2 years and of 5 years. Discuss about the shape of the two distributions:

```{r agehist2, exercise = TRUE}
```

```{r agehist2-solution}
#Thanks to the summary() function previously used, you were able to distinguish the min (23 years) and max (74 years). 
#We use these information to answer this question
hist(sleepapnea_clean$age, breaks=seq(20, 80, 2), main="distribution of age", xlab="age (years)")
hist(sleepapnea_clean$age, breaks=seq(20, 80, 5), main="distribution of age", xlab="age (years)")
```

f.  The `boxplot()` function summarize the quantile parameters for a quantitative variable. Below if the boxplot for the *age* variable. Interpret it:

```{r ageboxplot,  exercise = TRUE, exercise.eval = FALSE}
boxplot(sleepapnea_clean$age, main="distribution of age", xlab="age (years)")
```

Draw the box plot of age by gender group. Discuss about the shape of the two distributions.

```{r agebysexboxplot, exercise = TRUE}
```

```{r agebysexboxplot-solution}
boxplot(sleepapnea_clean$age ~  sleepapnea_clean$gender,  main="distribution of age by gender group", ylab="age (years)", xlab="gender")
```

g.  Compute the confidence interval of the age variable knowing the formula follows the Normal law assumption:

-   $1.96*\sigma/\sqrt{n}$

```{r agebyci}
bound <- 1.96*sd(sleepapnea_clean$age)/sqrt(length(sleepapnea_clean$age))
# upper bound
mean(sleepapnea_clean$age)+bound 
# lower bound
mean(sleepapnea_clean$age)-bound 
```

Note: The *epiDisplay* library propose the `ci()` function that computes the confidence interval. To use the function do not forget to load the library in your working session if not already done so.

## Part C - Univariate analysis

### 1. Summary by strata (group)

a.  First, we need to create the bmi groups. We propose you to `cut()` the bmi (quantitative) variable into 2 groups: $<25$ for "normal" and $>25$ for "overweight":

```{r cut, exercise = TRUE, exercise.eval = FALSE}
sleepapnea_clean$bmi_2grp <- cut(sleepapnea_clean$bmi, c(0, 25, 55), include.lowest = TRUE, right=FALSE)
levels(sleepapnea_clean$bmi_2grp) <- c("normal", "overweight")
```

**Practice:** We propose you to `cut()` the bmi (quantitative) variable into 3 groups: $<25$ for "normal", $[25 to 30[$ for "overweight", and $>30$ for "obese":

```{r, bmi3grp, exercise = TRUE}
```

```{r bmi3grp-solution}
sleepapnea_clean$bmi_3grp <- cut(sleepapnea_clean$bmi, c(0, 25, 30, 55), include.lowest = TRUE, right=FALSE)
levels(sleepapnea_clean$bmi_3grp) <- c("normal", "overweight", "obese")
```

b.  Second, we want to summarize the average of sleep apnea level by the 2 groups of bmi:

```{r meanbygroup, exercise = TRUE, exercise.eval = FALSE}
library(dplyr)
sleepapnea_clean %>% group_by(bmi_2grp) %>% summarise("mean_apnea"=mean(SleepApnea, na.rm = TRUE))
```

Note : The pipe operator (%>%) in R is used to “pipe” together a sequence of operations. It is most commonly used with the dplyr package in R to perform a sequence of operations on a data frame. The basic syntax for the pipe operator is: df %>% do_this_operation %>% then_do_this_operation %>% then_do_this_operation.... The keyboard shortcut for the pipe operator is CTRL+SHIFT+M. 

**Practice:** Repeat the computation for the bmi in 3 groups:

```{r, meanbygroup3, exercise = TRUE}
```

```{r meanbygroup3-solution}
library(dplyr)
sleepapnea_clean %>% group_by(bmi_3grp) %>% summarise("mean_apnea"=mean(SleepApnea, na.rm = TRUE))
```

**Practice:** Try with other quatitative variables of the data set such as age.

### 2. Statistical tests of association

**Example 1:** We would like to compare of the mean of sleep apnea among the 2 groups of bmi. 

What are the hypotheses tested here?

```{r sleepapneabmihypo, exercise = TRUE }

```

```{r sleepapneabmihypo-solution, exercise = TRUE }

#The hypotheses tested here are:
#H0: The average of sleep apnea among those with overweight is equal to the average of sleep apnea among those without overweight 
#H1: The average of sleep apnea among those with overweight is equal to the average of sleep apnea among those without overweight

```


```{r quiz, echo=FALSE}
question("What statistical tests could be of relevance to test these hypotheses? (select the two correct options)",
  answer("T-test", correct = TRUE),
  answer("ANOVA"),
  answer("Fisher test"),
  answer("Wilcoxon test", correct = TRUE),
  incorrect = "Incorrect. Give it another try.", 
  random_answer_order = TRUE,
  post_message = "Perfection! You got it. We have then two options: let's say, we go for the T-test option."
)
```
```{r quiz1, echo=FALSE}
question("What are the assumptions to be checked if the t-test was to be chosen? (select the two correct options)",
  answer("Normality", correct = TRUE),
  answer("Expected frequencies are lower than 5"),
  answer("Expected frequencies are higher than 5"),
  answer("Equal variance", correct = TRUE),
  incorrect = "Are you sure ? Give it another try!",
  random_answer_order = TRUE
)
```

a.  Since we consider the mean/average, we assume that we have normally distributed values of sleep apnea in the 2 bmi groups. Let's verify using the classical Shapiro test:

```{r apneabmi, exercise = TRUE, exercise.eval = FALSE}
by(sleepapnea_clean$SleepApnea, sleepapnea_clean$bmi_2grp, shapiro.test)
```

What are your conclusions?


```{r shapirotestint, exercise = TRUE }

```

```{r shapirotestint-solution, exercise = TRUE }

#We rejected H0 (here: normal distribution of sleep apnea in both group). 
#No need to check for the “equality of variance” assumption required to proceed with a t-test.

```


b.  Given the result of the Shapiro test, we choose to use the non-parametric test `wilcox.test()` to assess for a potential association. Try to apply the test and interpret the results:

```{r wilcox, exercise = TRUE, exercise.eval = FALSE}
wilcox.test(SleepApnea ~ bmi_2grp, data= sleepapnea_clean)
#Interpretation
#Based on the p-value obtained above: there is an association between sleep apnea and bmi (categorized in two groups)
```

Note: For most statistical tests of association, the *R* syntax is of type formula i.e. `func(y ~ x, data=mydata)` but you might want to look at the help pages of the different test functions for the details of their usage.

c.  Given the result of the Shapiro test, we can also try to transform the sleep apnea measures into a logarithm scale to approach a Normal distribution and use the parametric Student T test using `t.test()`. What is your interpretation?

```{r apnealog,  exercise = TRUE}

```

```{r apnealog-solution}
sleepapnea_clean$SleepApnea_log <- log(sleepapnea_clean$SleepApnea)
by(sleepapnea_clean$SleepApnea_log, sleepapnea_clean$bmi_2grp, shapiro.test) #check that the new created variable is normally distributed
t.test(SleepApnea_log ~ bmi_2grp, data=sleepapnea_clean)

#Interpretation
#We rejected H0 (p<0.05) : there is an association between SleepApnea_log and bmi (categorized in two groups) 
```
d. Are results different in question b and c?

To sum up : Transforming data to normal distribution is a method of changing the distribution by applying a mathematical function to each data value. This can help to achieve normality in modeling problems. Depending on the actual variable distribution, some common functions are logartithm and square root transformations, adding, subtracting, multiplying, but also dividing. Other options are to use the Box-Cox or Yeo-Johnson transforms. There are times when it's not possible to transform your data, and in such cases you need to use non-parametric tests.

**Example 2:** We would like to compare the distribution of sleep apnea measures among the 3 groups of bmi (*H0: The average number of pauses of breathing are the same in each bmi group*). Given the repartition of the patients among the 3 groups of bmi (non-normal), we propose to use the `kruskal.test()` non-parametric rank sum test to assess the differences (or not) between groups:

```{r kruskal, exercise = TRUE, exercise.eval = FALSE}
kruskal.test(SleepApnea ~ bmi_3grp, data= sleepapnea_clean)
```

What is your interpretation?

```{r sleepapneabmi3grpint, exercise = TRUE }

```

```{r sleepapneabmi3grpint-solution, exercise = TRUE }

#Interpretation
#We rejected H0 (p<0.05). We highlighted a statistically significant association between sleep apnea and bmi.

```

To identify which groups differ from the other(s) you can use the `dunn_test()` from the `rstatix` library

```{r dunn_test, exercise = TRUE, exercise.eval = FALSE}
library(rstatix)
dunn_test(SleepApnea ~ bmi_3grp, data= sleepapnea_clean)
```

In example 1 and 2, *bmi* was re-coded differently (2 modalities vs. 3). Does that make a difference in terms of the conclusions made?


**Example 3:** We would like to test whether there is an association between gender and bmi groups. 

What statistical tests to choose? What are the assumptions?
```{r genderbmihypo, exercise = TRUE}

```

```{r genderbmihypo-solution}

#Since two categorical variables are considered here, a chi2 test should be perform.

#H0: the distribution of people in the different bmi groups is equal among females and males 
#H1: the distribution of people in the different bmi groups is different among females and males
```


a.  We consider the gender and bmi groups which are categorical variables. We can perform a Fisher Exact test using `fisher.test()`:

```{r fisher, exercise = TRUE, exercise.eval = FALSE}
fisher.test(sleepapnea_clean$gender, sleepapnea_clean$bmi_2grp)

#Interpretation
#To be completed according to the p-value obtained above: we failed to reject H0 (p>0.05). There is no relation between gender and bmi.

```

b.  A similar test is the Chi Square test that you can apply using `chisq.test()`. Have a try and interpret the results:

```{r chi2, exercise = TRUE}

```

```{r chi2-solution}
chisq.test(sleepapnea_clean$gender, sleepapnea_clean$bmi_2grp)
```
To wrap up

The hypotheses of the Fisher’s exact test are the same than for the Chi-square test, that is:

H0 : the variables are independent, there is no relationship between the two categorical variables. Knowing the value of one variable does not help to predict the value of the other variable.
H1: the variables are dependent, there is a relationship between the two categorical variables. Knowing the value of one variable helps to predict the value of the other variable.

Remember that the Fisher’s exact test is used when there is at least one cell in the contingency table of the expected frequencies below 5. To retrieve the expected frequencies, use the chisq.test() function together with $expected:

```{r chisq-expected, exercise = TRUE, exercise.eval = FALSE}

chisq.test(sleepapnea_clean$gender, sleepapnea_clean$bmi_2grp)$expected

```
Tip: although it is a good practice to check the expected frequencies before deciding between the Chi-square and the Fisher test, it is not a big issue if you forget. As you can see above, when doing the Chi-square test in R (with chisq.test()), a warning such as “Chi-squared approximation may be incorrect” will appear. This warning means that the smallest expected frequencies is lower than 5. Therefore, do not worry if you forgot to check the expected frequencies before applying the appropriate test to your data, R will warn you that you should use the Fisher’s exact test instead of the Chi-square test if that is the case.


## Part D - More univariate analysis

### 1. Is there an association between sleep apnea and cholesterol classes ?

a. Define a new categorical variable (*Cholesterol_tert*) using the tertiles of the distribution of the *cholesterol* variable.

```{r CholesterolClassesSleepApnea, exercise = TRUE}

```

```{r CholesterolClassesSleepApnea-solution}

where2break <- quantile(sleepapnea_clean$cholesterol, c(0:3/3))
sleepapnea_clean$Cholesterol_tert<- cut(sleepapnea_clean$cholesterol,breaks = where2break, 
                               include.lowest = TRUE,right=FALSE)
table(sleepapnea_clean$Cholesterol_tert) #to check the distribution of your new variable

```


b. Plot the distribution of the *SleepApnea* variable by group of *Cholesterol_tert*.

```{r CholesterolClassesSleepApneaPlot, exercise = TRUE}

```

```{r CholesterolClassesSleepApneaPlot-solution}
boxplot(sleepapnea_clean$SleepApnea ~  sleepapnea_clean$Cholesterol_tert,  main="Distribution of SleepApnea by concentration of cholesterol", ylab="Sleep Apnea (number of pauses of breathing)", xlab="Concentration of cholesterol (tertiles)")

```
c. Formulate the statistical hypotheses to compare *SleepApnea* variable by cholesterol group.

```{r CholesterolClassesSleepApneaHypo, exercise = TRUE}

```

```{r CholesterolClassesSleepApneaHypo-solution}

#H0 :  The average number of pauses of breathing are the same in each group
#H1 :  The average number of pauses of breathing differ in at least one case compare to the others

```

d. Test for the normality of the distribution of *SleepApnea* variable by group of *Cholesterol_tert*.


```{r quiz2, echo=FALSE}
question("For this test, what is the H0 hypothesis? (select the correct answer)",
  answer("The distribution of the SleepApnea variable in the different groups of cholesterol concentration is not different from a Normal distribution", correct = TRUE),
  answer("The distribution of the SleepApnea variable in the different groups of cholesterol concentration is different from a Normal distribution"),
  answer("The distribution of the SleepApnea variable is different from a Normal distribution"),
  answer("None of the above"),
  incorrect = "Incorrect. Give it another try.", 
  random_answer_order = TRUE,
  post_message = "Alright! You got it. Now, let's run the test and interpret the result."
)
```

```{r CholesterolClassesSleepApneaNormality, exercise = TRUE}

```

```{r CholesterolClassesSleepApneaNormality-solution}

by(sleepapnea_clean$SleepApnea, sleepapnea_clean$Cholesterol_tert, shapiro.test)
#We rejected H0. A non-parametric test is thus needed to test the association of interest here.

```
e. According to your previous findings, use the appropriate function and associated post-hoc test (if needed) to verify your hypothesis. Interpret your results.

```{r CholesterolClassesSleepApneaKruskal, exercise = TRUE}

```

```{r CholesterolClassesSleepApneaKruskal-solution}

kruskal.test(formula = SleepApnea ~ Cholesterol_tert, data = sleepapnea_clean)
#Interpretation
#We failed to reject H0. There is no overall association between these two variables. No need for a post-hoc analysis.

```

f. Another option would be to use the *SleepApnea_log* variable. Re-run the analysis with this variable and using the appropriate test. Interpret your results.

```{r CholesterolClassesSleepApnealog, exercise = TRUE}

```

```{r CholesterolClassesSleepApnealog-solution}


```

g. Was the categorization of the *cholesterol* variable necessary ? Justify with a plot.

```{r CholesterolClassesSleepApneaCat, exercise = TRUE}

```

```{r CholesterolClassesSleepApneaCat-solution}

hist(sleepapnea_clean$cholesterol)
#The distribution of this variable seems normal. A transformation was thus not necessary.

```


### 2. Is there an association between sleep apnea and triglyceride classes ?

a. Define a new categorical variable (*Triglyceride_tert*) using the tertiles of the distribution of the *Triglyceride* variable.

```{r TriglycerideClassesSleepApnea, exercise = TRUE}

```

```{r TriglycerideClassesSleepApnea-solution}

where2break <- quantile(sleepapnea_clean$Triglyceride, c(0:3/3))
sleepapnea_clean$Triglyceride_tert<- cut(sleepapnea_clean$Triglyceride,breaks = where2break, 
                               include.lowest = TRUE,right=FALSE)
table(sleepapnea_clean$Triglyceride_tert)

```


b. Plot the distribution of the "SleepApnea" variable by group of *Triglyceride_tert*.

```{r TriglycerideClassesSleepApneaPlot, exercise = TRUE}

```

```{r TriglycerideClassesSleepApneaPlot-solution}
boxplot(sleepapnea_clean$SleepApnea ~  sleepapnea_clean$Triglyceride_tert,  main="Distribution of SleepApnea by concentration of triglyceride", ylab="Sleep Apnea (number of pauses of breathing)", xlab="Concentration of triglyceride (tertiles)")

```
c. Formulate the statistical hypotheses to compare "SleepApnea" variable by triglyceride group.

```{r TriglycerideClassesSleepApneaHypo, exercise = TRUE}

```

```{r TriglycerideClassesSleepApneaHypo-solution}

#H0 :  The average number of pauses of breathing are the same in each group
#H1 :  The average number of pauses of breathing differ in at least one case compare to the others

```

d. Test for the normality of the distribution of *SleepApnea* variable by group of *Triglyceride_tert*.

```{r TriglycerideClassesSleepApneaNormality, exercise = TRUE}

```

```{r TriglycerideClassesSleepApneaNormality-solution}

by(sleepapnea_clean$SleepApnea, sleepapnea_clean$Triglyceride_tert, shapiro.test)

```
e. According to the previous findings, use the appropriate function and associated post-hoc test (if needed) to verify your hypothesis. Interpret your results.


```{r TriglycerideClassesSleepApneaKruskal, exercise = TRUE}

```

```{r TriglycerideClassesSleepApneaKruskal-solution}

kruskal.test(formula = SleepApnea ~ Triglyceride_tert, data = sleepapnea_clean)
#Interpretation
#We failed to reject H0. There is no association between sleep apnea and triglyceride concentration (categorized the way it is here). 
#No need, thus, to conduct a post-hoc test.

```

f. Try to repeat the steps from b to e with the *Triglyceride_Cl_Ref* variable.

```{r TriglycerideClassesSleepApneaKruskal2, exercise = TRUE}

```

```{r TriglycerideClassesSleepApneaKruskal2-solution}
#Boxplot
boxplot(sleepapnea_clean$SleepApnea ~  sleepapnea_clean$Triglyceride_Cl_Ref,  main="Distribution of SleepApnea by concentration of triglyceride", ylab="Sleep Apnea (number of pauses of breathing)", xlab="Concentration of triglyceride (biological cut-off)")

#Hypothesis
#H0 :  The average number of pauses of breathing are the same in each group
#H1 :  The average number of pauses of breathing differ in at least one case compare to the others

#Normality check
by(sleepapnea_clean$SleepApnea, sleepapnea_clean$Triglyceride_Cl_Ref, shapiro.test)
#An error message appears following this code line
#This is because few people (only 2) are considered as "very high" with regards to the triglyceride concentration  
#Which makes it impossible to conduct the test

#Creation of a new variable with 3 modalities
sleepapnea_clean$Triglyceride_Cl_Ref_bis <- sleepapnea_clean$Triglyceride_Cl_Ref
levels(sleepapnea_clean$Triglyceride_Cl_Ref_bis)
levels(sleepapnea_clean$Triglyceride_Cl_Ref_bis)[4] <- "High"
table(sleepapnea_clean$Triglyceride_Cl_Ref_bis)

#Test 
kruskal.test(formula = SleepApnea ~ Triglyceride_Cl_Ref_bis, data = sleepapnea_clean)

#Interpretation
#We failed to reject H0. There is no association between those two variables.

```

g. Compare the results when using the *Triglyceride_tert* variable and the *Triglyceride_Cl_Ref* variable. What are your conclusions ?

```{r comparetriglysleepapnea, exercise = TRUE}

```

```{r comparetriglysleepapnea-solution}

#No matter how the Triglyceride continuous variable is categorized (quantile-based or clinically-based cut-offs), there is no association between sleep apnea and the triglyceride concentration.

```


### 3. Is having more comorbities associated with sleep apnea ?

Let's consider living with obesity (bmi >30kg/m2), a triglyceride concentration > 5g/L and a cardiac frequency >85 bpm (beats per minute) as comoribidities.

a. Based on the original continuous variables, create the three corresponding binary variables. 

```{r ComorbiditiesSleepApneaComorb, exercise = TRUE}

```

```{r ComorbiditiesSleepApneaComorb-solution}

sleepapnea_clean$obese <- ifelse(sleepapnea_clean$bmi < 30, 0, 1) # obese yes(1) or no(0)
sleepapnea_clean$triglyceride_high <- ifelse(sleepapnea_clean$Triglyceride <= 5, 0, 1)
sleepapnea_clean$CardiacFreq_high <- ifelse(sleepapnea_clean$CardiacFreq <= 85, 0, 1)

```

b. Create a score ranging from 0 to 3 corresponding to the sum of comorbidities then create a factor variable (named *bad_shape*). Check the distribution of this new variable and make the appropriate changes if needed.

```{r ComorbiditiesSleepApneaSum, exercise = TRUE}

```

```{r ComorbiditiesSleepApneaSum-solution}
# Sum of comorbidities
sleepapnea_clean$bad_shape <- rowSums(sleepapnea_clean[ , c("obese", "triglyceride_high", "CardiacFreq_high")])
table(sleepapnea_clean$bad_shape)
# Transform into factor
sleepapnea_clean$bad_shape <- factor(sleepapnea_clean$bad_shape, levels=c(0:3),
                          labels=c("no", "1 comorbidity", "2 comorbidities", 
                                   "3 comorbidities"))
table(sleepapnea_clean$bad_shape)
# group level number 4 with number 3 since only 1 person in "3 comorbidities"
levels(sleepapnea_clean$bad_shape)[4] <- "2 comorbidities"
table(sleepapnea_clean$bad_shape)
# rename level 3 to "2 comorbidities or more"
levels(sleepapnea_clean$bad_shape)[3] <- "2 comorbidities or more"
table(sleepapnea_clean$bad_shape)

```

c. Conduct the appropriate test to investigate the association between the *SleepApnea* and the newly created variable *bad_shape*.

```{r ComorbiditiesSleepApneaTest, exercise = TRUE}

```

```{r ComorbiditiesSleepApneaTest-solution}
#Hypotheses
#H0: the average of sleep apnea is similar no matter the number of comorbidities  
#H1: the average of sleep apnea is different according to the number of comorbidities

#Normality check
by(sleepapnea_clean$SleepApnea, sleepapnea_clean$bad_shape, shapiro.test)

#Test
kruskal.test(formula = SleepApnea ~ bad_shape, data = sleepapnea_clean)

#Interpretation
#We rejected H0 (though at the limit of the significance). There is an association between sleep apnea and comorbidities. 
#A post-hoc test can be undertaken.

library(rstatix)
dunn_test(formula = SleepApnea ~ bad_shape, data = sleepapnea_clean)

```

d. Repeat the analysis (with the appropriate test) by considering the *SleepApnea* variable as a dichotomous one (cut-off : 70 pauses of breathing). Use the ifelse() function (?ifelse) to create this new variable.

```{r ComorbiditiesSleepApneaTest2, exercise = TRUE}

```

```{r ComorbiditiesSleepApneaTest2-solution}

#Create the dichotomous variable
sleepapnea_clean$SleepApnea_grp <-  ifelse(sleepapnea_clean$SleepApnea < 70, "normal", "high") 

#Hypothesis
# H0: Equal distribution of people with ou without comorbidities among the high and normal sleep apnea
# H1: Different distribution

#Distribution (contengency table)
round(prop.table(xtabs( ~ bad_shape + SleepApnea_grp, data = sleepapnea_clean), 2)*100,2)
#Among those with a normal number of pauses of breathing, around 67% has no comorbidity against only around 28% among #those with a higher number of pauses of breathing

#Test
fisher.test(sleepapnea_clean$bad_shape, sleepapnea_clean$SleepApnea_grp)

#Interpretation
#Based on the p-value obtained above: We rejected H0 (p<0.05). There is an association between sleep apnea and comorbidities.

```

## Part E - Linear regression analysis

Simple linear regression is a statistical approach that allows to assess the linear relationship between two quantitative variables. More precisely, it enables the relationship to be quantified and its significance to be evaluated. Linear regression is one of the most basic statistical models out there and it has been around since the 19th century. 

Simple linear regression is an asymmetric procedure in which: 
- one of the variable is considered the response or the variable to be explained. It is also called **dependent variable**, and is represented on the y-axis.
- the other variable is the explanatory or also called **independent variable**, and is represented on the x-axis.

### Is there a linear association between sleep apnea and bmi?

a. Which variable is the dependent variable here ? Which variable is the independent one?

```{r SleepApneaBmi, exercise = TRUE}

```

```{r SleepApneaBmi-solution}

#The "SleepApnea" variable is the dependent variable
#The "bmi" variable is the independent variable

```

The *SleepApnea* variable is somehow skewed, so we prefer to use its log transformed version (created before) to assess any linear association.

b. Represent and comment on the relationship between *SleepApnea_log* and *bmi* using the ggplot() function (?ggplot).

```{r SleepApnealogBmiGraph, exercise = TRUE}

```

```{r SleepApnealogBmiGraph-solution}
ggplot(sleepapnea_clean, aes(bmi, SleepApnea_log)) + 
  geom_point(color = "dark blue") +
  geom_smooth(method = "lm", se=FALSE, color="red", 
              formula = y ~ x)
```

c. What does the following warning mean : "Warning: Removed 1 rows containing non-finite values (`stat_smooth()`)." ?

```{r SleepApnealogBmiWarning, exercise = TRUE}

```

```{r SleepApnealogBmiWarning-solution}

#There is one missing value in the SleepApnea_log variable hence the fact that one "row" was removed 

```

d. Formulate the statistical hypotheses to test the linear association between *bmi* and *SleepApnea_log*.

```{r SleepApnealogBmiHypo, exercise = TRUE}

```

```{r SleepApnealogBmiHypo-solution}

#H0 : Beta1 = 0, bmi has no effect on sleep apnea  
#H1 : Beta1 not equal to 0, changes in bmi are associated with changes in sleep apnea

#or

#H0: There is no linear association between sleepapnea and bmi
#H1: There is a linear association between sleepapnea and bmi

```

A linear regression can be calculated in R with the command lm.

e. Apply a simple linear regression model using the function called lm() and visually assess the quality (the assumptions) of the linear regression using the plot() function.

```{r SleepApnealogBmiReg, exercise = TRUE}

```

```{r SleepApnealogBmiReg-solution}

model <- lm(SleepApnea_log ~ bmi, data = sleepapnea_clean)
model
summary(model)
coefficients(model)          # Mean effects size
confint(model, level = 0.95) # Compute confidence intervals

layout(matrix(1:4, ncol=2))
plot(model)
layout(1)

```

**Note :** In contrast to p-values, confidence intervals indicate the direction of the effect studied. Conclusions about statistical significance are also possible with the help of the confidence interval. If the confidence interval does not include the value of zero effect, it can be assumed that there is a statistically significant result (cf null hypothesis, i.e., is Beta different from 0 or not ?).

**Reminder :**

-The confidence interval is a range of values calculated by statistical methods which includes the desired true parameter (here, the beta) with a probability defined in advance. The confidence level of 95% is usually selected. This means that the confidence interval covers the true value in 95 of 100 studies performed.  

-The size of the confidence interval depends on the sample size and the standard deviation of the study groups. If the sample size is large, this leads to "more confidence" and a narrower confidence interval. If the confidence interval is wide, this may mean that the sample is small. If the dispersion is high, the conclusion is less certain and the confidence interval becomes wider. Finally, the size of the confidence interval is influenced by the selected level of confidence. A 99% confidence interval is wider than a 95% confidence interval. In general, with a higher probability to cover the true value the confidence interval becomes wider.

(*du Prel et al., 2009*)

f. Interpret the results and the quality of your linear regression.

```{r SleepApnealogBmiInt, exercise = TRUE}

```

```{r SleepApnealogBmiInt-solution}

#For 1 unit increase in bmi, there is 0.029 increase in SleepApnea_log

#All the assumptions seems fulfilled.

```

If you are not a hundred percent sure about your residual diagnostic, you can perform some statistical tests.  

```{r assumptionstests}

#check the normality of residuals numerically:
#H0 : the distribution of the residuals is normal
#H1 : the distribution of the residuals is not normal

shapiro.test(model$residuals)

#check the homoscedasticity of the residuals numerically
library(car)
ncvTest(model)

#check the independence of the residuals 
library(lmtest)
dwtest(model)
```

g. What represents the "Intercept" of your model ?

```{r SleepApnealogBmiIntercept, exercise = TRUE}

```

```{r SleepApnealogBmiIntercept-solution}

#The intercept is the mean value of the dependent variable Y (SleepApnea_log, here) when the independent variable X (bmi, here) takes the value 0.

```

### Is there a linear association between sleep apnea and age? 

Following the same steps as in the previous section, test the presence of a linear association between sleep apnea and age.

```{r SleepApneaAge, exercise = TRUE}

```

```{r SleepApneaAge-solution}

#The "SleepApnea" variable is the dependent variable
#The "age" variable is the independent variable

#Represent and comment on the relationship between *SleepApnea_log* and *age* using the ggplot() function.

ggplot(sleepapnea_clean, aes(age, SleepApnea_log)) + 
  geom_point(color = "dark blue") +
  geom_smooth(method = "lm", se=FALSE, color="red", 
              formula = y ~ x)

#Formulate the statistical hypotheses to test the linear association between *age* and *SleepApnea_log*.

#H0 : Beta1 = 0, age has no effect on sleep apnea  
#H1 : Beta1 not equal to 0, changes in age are associated with changes in sleep apnea
#or
#H0: There is no linear association between sleepapnea and age
#H1: There is a linear association between sleepapnea and age


#Apply a simple linear regression model using the function called lm() and visually assess the quality of the linear #regression using the plot() function.

model <- lm(SleepApnea_log ~ age, data = sleepapnea_clean)
model
summary(model)
coefficients(model)          # Mean effects size
confint(model, level = 0.95) # Compute confidence intervals

layout(matrix(1:4, ncol=2))
plot(model)
layout(1)

#Interpret the results
#There is no association between age and SleepApnea_log

```

### Is there a linear association between sleep apnea and cardiac frequency ? 

Following the same steps as in the previous section test the presence of a linear association between sleep apnea and cardiac frequency.

```{r SleepApneaCardiacFreq, exercise = TRUE}

```

```{r SleepApneaCardiacFreq-solution}

#The "SleepApnea" variable is the dependent variable
#The "CardiacFreq" variable is the independent variable

#Represent and comment on the relationship between *SleepApnea_log* and *CardiacFreq* using the ggplot() function.

ggplot(sleepapnea_clean, aes(CardiacFreq, SleepApnea_log)) + 
  geom_point(color = "dark blue") +
  geom_smooth(method = "lm", se=FALSE, color="red", 
              formula = y ~ x)

#Formulate the statistical hypotheses to test the linear association between *CardiacFreq* and *SleepApnea_log*.

#H0 : Beta1 = 0, cardiac frequency has no effect on sleep apnea  
#H1 : Beta1 not equal to 0, changes in cardiac frequency are associated with changes in sleep apnea
#or
#H0: There is no linear association between sleepapnea and cardiac frequency
#H1: There is a linear association between sleepapnea and cardiac frequency


#Apply a simple linear regression model using the function called lm() and visually assess the quality of the linear #regression using the plot() function.

model <- lm(SleepApnea_log ~ CardiacFreq, data = sleepapnea_clean)
model
summary(model)
coefficients(model)          # Mean effects size
confint(model, level = 0.95) # Compute confidence intervals

layout(matrix(1:4, ncol=2))
plot(model)
layout(1)

#Interpret the results
#For 1 unit increase in cardiac frequency, there is 0.009 increase in SleepApnea_log 

```

You have performed simple linear regressions. Simple linear regression models can be too simplistic and the conclusions may be wrong. In reality, diseases are most often multi-factorial, thus, a particular relation of interest might be **confounded** by various other factors.

A **confounder** is an extraneous variable whose presence affects the variables being studied so that the results do not reflect the actual relation between the variables under study. 

In **multiple linear regression** (*see Part G*), investigators can include many potential **confounders** at one time. The process of accounting for them is also called **adjustment** and comparing the results of simple and multiple linear regressions can clarify that: how much the confounders in the model distort the relation between exposure and outcome?


## Part F - Logistic regression analysis

### Is there an association between sleep apnea (considered as a binary variable) and various socio-demographic and biological factors ?

Previously, was created the *SleepApnea_grp* variable (Part D). This variable will be considered as our dependent variable.

```{r quizlogistic, echo=FALSE}
question("What are the main assumptions of logistic regression? (select the two correct options)",
  answer("Independence of observations", correct = TRUE),
  answer("Homoscedasticity of residuals"),
  answer("Normality of residuals"),
  answer("Linearity of continuous explanatory variables and the log-odds outcome", correct = TRUE),
  incorrect = "Incorrect. Give it another try.", 
  random_answer_order = TRUE,
  post_message = "Correct! For the following questions/tests, consider that these assumptions (when applicable) are fulfilled."
)
```

a. Using the glm() function, run a logistic regression to investigate the association between sleep apnea and age. For logistic regression, use the following argument : family = "binomial".

```{r SleepApneaLogisticAge, exercise = TRUE}

```

```{r SleepApneaLogisticAge-solution, exercise = TRUE}
#If using the *SleepApnea_grp* variable without any transformation, you will get an error message as follows:
#"y values must be 0 <= y <= 1" 
#because for a logistic regression using the glm function the dependent variable should take two modalities as 0 and 1

#create a new *SleepApnea_grp01* variable 
sleepapnea_clean$SleepApnea_grp01 <- ifelse(sleepapnea_clean$SleepApnea_grp %in% c("high"), 1, 0)

#run the analysis with the newly created variable
logit1 <- glm(formula = SleepApnea_grp01 ~ age, data = sleepapnea_clean, family = "binomial"(link = "logit"))
summary(logit1)

exp(coef(logit1))
exp(confint(logit1))

```

b. Interpret your results.

```{r SleepApneaLogisticAgeInter, exercise = TRUE}

```

```{r SleepApneaLogisticAgeInter-solution, exercise = TRUE}

#There is no association between age and sleep apnea. Or : an increase in age is not associated with an increase in the probability of having high sleep apnea.
#Results are similar than those with the sleep apnea variable as a continuous variable.

```

c. Repeat the analysis conducted in question a. with the following independent variables : gender, cholesterol (continuous), cardiac frequency (continuous) and bmi (continuous). Compare some results with the analyses you conducted considering sleep apnea as a continuous variable (part E).

```{r SleepApneaLogisticVarious, exercise = TRUE}

```

```{r SleepApneaLogisticVarious-solution}

#CardiacFreq as the independent variable
logit2 <- glm(formula = SleepApnea_grp01 ~ CardiacFreq, data = sleepapnea_clean, family = "binomial"(link = "logit"))
summary(logit2)
exp(coef(logit2))
exp(confint(logit2)) 
#Interpretation : there is an association between these two variables

#bmi as the independent variable
logit3 <- glm(formula = SleepApnea_grp01 ~ bmi, data = sleepapnea_clean, family = "binomial"(link = "logit"))
summary(logit3)
exp(coef(logit3))
exp(confint(logit3)) 
#Interpretation : there is an association between these two variables

#cholesterol as the independent variable
logit4 <- glm(formula = SleepApnea_grp01 ~ cholesterol, data = sleepapnea_clean, family = "binomial"(link = "logit"))
summary(logit4)
exp(coef(logit4))
exp(confint(logit4)) 
#Interpretation : there is no association between these two variables

#age as the independent variable
logit5 <- glm(formula = SleepApnea_grp01 ~ age, data = sleepapnea_clean, family = "binomial"(link = "logit"))
summary(logit5)
exp(coef(logit5))
exp(confint(logit5)) 
#Interpretation : there is no association between these two variables


```

d. **Advanced practice** Instead of running various models one after the other (solution - question c), a good practice is to create a loop or use the *purrr* library methods.

```{r SleepApneaLogisticVariousloop, exercise = TRUE}

```

```{r SleepApneaLogisticVariousloop-solution}
#Loading necessary packages
library(purrr)
library(stringr)
library(tidyr)
library(broom)

#To run the models on several exposure variables to produce univariate odds ratios, you can use the approach below : 

explanatory_vars <- c("age", "bmi", "cholesterol", "CardiacFreq") #Create a vector of column names of the explanatory variables
explanatory_vars %>% str_c("SleepApnea_grp01 ~ ", .)

models <- explanatory_vars %>%       # begin with variables of interest
  str_c("SleepApnea_grp01 ~ ", .) %>%         # combine each variable into formula ("outcome ~ variable of interest")
  
  # iterate through each univariate formula
  map(                               
    .f = ~glm(                       # pass the formulas one-by-one to glm()
      formula = as.formula(.x),      # within glm(), the string formula is .x
      family = "binomial",           # specify type of glm (logistic)
      data = sleepapnea_clean)) %>%          # dataset
  
  # tidy up each of the glm regression outputs from above
  map(
    .f = ~tidy(
      .x, 
      exponentiate = T,           # exponentiate 
      conf.int = T)) %>%          # return confidence intervals
  
  # collapse the list of regression outputs in to one data frame
  bind_rows() 

  models
```

Note: Some analyses conducted in *Part F* are often called **sensitivity analyses** in research papers. **Sensitivity analyses** play a crucial role in assessing the robustness of the findings or conclusions based on primary analyses of data in clinical trials or epidemiological studies. They are a critical way to assess the impact, effect or influence of key assumptions or variations—such as different methods of analysis, definitions of outcomes, protocol deviations, missing data, and outliers—on the overall conclusions of a study.

## Part G: Multiple linear and logistic regressions

Multiple (linear) regression can be used to assess the relationship between two variables while taking into account the effect of other variables. By taking into account the effect of other variables (i.e., *adjusting for* other potential variables influencing the studied relation), we cancel out the effect of these other variables in order to isolate and measure the relation between the two variables of interest. This point is the main difference with simple linear regression.

Let's focus on the relation between sleep apnea (continuous) and bmi. Age and gender are potential *confounders* with regards to the latter relation (based on the litterature - cf the *Introduction* section about sleep apnea).

```{r MultiLinRegExample}

model_multi <- lm(SleepApnea_log ~ bmi + age + gender, data = sleepapnea_clean)
model_multi
summary(model_multi)
coefficients(model_multi)          # Mean effects size
confint(model_multi, level = 0.95) # Compute confidence intervals

```

Here, even though we **controlled for** or **adjusted for** *age* and *gender*, *bmi* is still associated with *SleepApnea_log*. The *bmi* coefficient is, however, slightly different (higher) from the one obtained in *Part E* - question e (0.034 vs. 0.029) and its interpretation changed : For 1 unit increase in *bmi*, there is 0.034 increase in *SleepApnea_log*, holding all other x variables constant (or adjusting for *age* and *gender*).

The intercept in the previous summary output can be interpreted as (even though biologically there is no sense in the following sentence): the average number of abnormal pauses during sleep for female, when their bmi=0 and age=0. The summary output of our regression allows us to identify the reference category used for a factor variable x, here *gender* : the reference category is the one not appearing in the regression output. **Tips:** Most of the time, we need to manually set the reference factor level in the linear regression model. To do so we use the relevel() function of the R Language. The relevel() function is used to reorder levels of a factor vector. The levels of a factor vector are re-ordered so that the level specified by the user is first and the others are moved down one step.

**Important note:** Presenting and interpreting estimates of effect measures for secondary risk factors (confounders - here age and gender) obtained from the same model as that used to estimate the primary exposure (here, our association of interest is "bmi -> sleep apnea") effects can lead readers astray in a number of ways. The interpretation of a confounder effect estimate may be different than for the exposure effect estimate (possibility of residual confounding and, in some circumstances, total effects are not warranted).

**Final note:** Make sure that, statiscally speaking, there is a sense in interpreting a coefficient (i.e., if p value > 0.05, there is no need to interpret the coefficient(s)).

Don't forget to check the assumptions for this model.

```{r MultiLinRegExample}

#Visually
plot(model_multi)
#Numerically
#Cf Part E - simple linear regression

```

What may be the problem when including various independent variables (i.e., the potential confounders) in a model ?

```{r MultiLinRegProb, exercise = TRUE}

```
```{r MultiLinRegProb-solution}

# If the explanatory variables are perfectly correlated, you will face these problems:
# -Inflated coefficients
# -Underestimated Student T test (non-significant p-values)
# -Values and signs of the coefficients are incoherent with common knowledge
# -Unsteady results, adding or deleting observation strongly modify the values and signs of the coefficients

#One way to detect multi-colinearity in R is using the following lines:
library(car)
vif(model) #all VIF values are below 10, it seems that multi-colinearity is thus not a concern here

#Or you can use the mctest package and the imcdiag() function
library(mctest)
imcdiag(model_multi)

```

Depending on your goal/research question, the approach that you take to fitting a model may change:
- **Predictive** : including all predictors of your outcome/dependent variable is needed.
- **Comparative/Hypothesis Testing** (the case in the example above) : including only true confounders of the x-y relation is of importance. However, it can be difficult to control for all of these factors in any study. *"All models are wrong, but some are useful"*.

Let's now change our objective to *"predict sleep apnea"*.

Here again, we would like to avoid considering too many variables, and thus, **overfitting**, i.e., the model fits too closely or exactly a particular set of data,
and may therefore fail to fit to additional data or predict future observations reliably. The variance of any one model would tell us how robust the performance of this particular model is, meaning if we were to slightly change the values of our data points, how much would our performance fluctuate?

One way to counter **overfitting** is automatic variable selection (backward, forward, stepwise).

Conduct such an approach with *SleepApnea_log* as a dependent variable (use the step() function).

```{r MultiLinRegSelection, exercise = TRUE}

```
```{r MultiLinRegSelection-solution}

#The step() function can not proceed with a data set presenting missing values
#We thus have to create a new data set only containing "complete cases" (units with values for all the considered variables)
sleepapnea_clean_noNA <- na.omit(sleepapnea_clean) 

#Conducting the selection
modelsel = lm(SleepApnea_log ~ bmi + age + gender + cholesterol + creatinine + CardiacFreq + diabetes + Triglyceride_Cl_Ref, data= sleepapnea_clean_noNA)
modelStep <- step(modelsel, direction = "both")

#The model containing the following variables was retained : bmi, age, gender, creatinine, CardiacFreq, Triglyceride_Cl_Ref

```

Is the model retained above (in the previous exercise) better than the full one (i.e., containing all the potential predictors: *bmi*, *age*, *gender*, *creatinine*, *CardiacFreq*, *Triglyceride_Cl_Ref* but also *diabetes* and *cholesterol* ? 
Use the AIC() function to respond. The **Akaike information criterion (AIC)** is a good test for model fit. AIC calculates the information value of each model by balancing the variation explained against the number of parameters used.
Using the anova() function is also possible - models being compared need to be *"nested"*.

```{r MultiLinRegSelectionbest, exercise = TRUE}

```
```{r MultiLinRegSelectionbest-solution}

#Need to run a model with all potential predictors (with the "complete-cases" data set)
modelfull <- lm(SleepApnea_log ~ bmi + age + gender + cholesterol + creatinine + CardiacFreq + diabetes + Triglyceride_Cl_Ref, data = na.omit(sleepapnea_clean))
modelfull

#Checking with the AIC() function
AIC(modelfull, modelStep) #the smaller the better 
#Conclusion: the full model is not the better one (highest AIC)

#Checking with the anova() function to select the best (nested) model
#If you have two or more models that are subsets of a larger model, 
#you can use anova() to check if the additional variable(s) contribute to the predictive ability of the model. 

anova(modelfull, modelStep)

#For each row in the output, the anova() tests a hypothesis comparing two models.
#The null hypothesis is that the two models are equal in fitting the data (i.e. the Y variable),
#while, the alternative hypothesis is that the full model is better (i.e. the additional X variable(s) improve(s) the model).
#If we fail to reject the null hypothesis, it is then better to keep the model with less variables.
#If we reject the null hypothesis, model 2 (the one selected after the stepwise procedure) indeed provides a significantly better fit to the data compared to model 1 (the full model).

#The anova() test can add to the evidence from the AIC() output.

```

**Practice**: Repeat the analyses with the *SleepApnea_grp01* variable. Comment.

```{r MultiLinRegSelectionLogbest, exercise = TRUE}

```
```{r MultiLinRegSelectionLogbest-solution}
modelselLog = glm(SleepApnea_grp01 ~ bmi + age + gender + cholesterol + creatinine + CardiacFreq + diabetes + Triglyceride_Cl_Ref, family= "binomial", data= na.omit(sleepapnea_clean))
modelStepLog <- step(modelselLog, direction = "both")
modelStepLog

#Need to run a model with all potential predictors (with the "complete-cases" data set)
modelfullLog <- glm(SleepApnea_grp01 ~ bmi + age + gender + cholesterol + creatinine + CardiacFreq + diabetes + Triglyceride_Cl_Ref, family= "binomial", data= na.omit(sleepapnea_clean))
modelfullLog

AIC(modelfullLog, modelStepLog) #the smaller the better 

#Interpretation/conclusion: 
#Contrary to what was obtained with the continuous SleepApnea_log variable,
#only the following variables were retained by the automatic variable selection: bmi, gendermale, creatinine, CardiacFreq

```

A final note: While helping in managing overfitting, automated procedures also exclude observations that are missing any of the predictors considered, not just those that end up in the final model; this can (drastically) reduce the sample size and, in turn, somehow, still increase the likelihood of overfitting.
Readers and authors should be skeptical of models fit with automated selection procedures, including forward, backward, or stepwise selection. These models are highly likely to be overfit, including containing variables that have no relationship with the outcome and variables for which the effect sizes have been overestimated. In particular, if the number of predictors considered is large and the sample size is small to moderate, then the results are unlikely to be reproducible. Researchers should instead rely on expert judgment during model building and/or should work closely with a statistician. Newer automated procedures for model selection exist but have yet to be widely adopted in the medical literature (Sainani, 2013).

